# スケールアウト
ここでは、コンテナ環境をスケールアウトする方法を４つ説明します。
|  No  |  方法  |　説明|
| ---- | ---- | ---- |
| ①-1 | Podのスケールアウト/手動 | 稼動するPod数を手動で増やします。 |
| ①-2 | Podのスケールアウト/自動 | 負荷に応じてPod数を自動で増やします。HPAと呼ばれます。 |
| ②-1 | ノードのスケールアウト/手動 | Workerノード数を手動で増やします。 |
| ②-2 | ノードのスケールアウト/自動 | Workerノード数を負荷に応じて自動で増やします。 |

手動で増やすか自動で増やすか、

Pod数かノード数か、

ということになります。

それでは、順番にやっていきましょう。
<br><br>
## ①-1 ：Podのスケールアウト/手動
まずは、サンプル用のWebサーバーをデプロイして、Podの数を増やします。


サンプル用のWebサーバーでは、アクセス先のPodの内部IPアドレスを表示します。

複数のPodに正しく負荷分散されれば、アクセスするたびに、異なるPodのIPアドレスが表示されることになります。

```
$ oc new-project scale-test001

$ oc create deployment scaling --image quay.io/redhattraining/scaling:v1.0

$ oc get pod -o wide
```

ルートを作成します。
```
$ oc expose deployment/scaling --port 80 --target-port 8080
$ oc expose svc/scaling

$ oc get route

$ curl http://ルート名/
```

Pod数を2つに増やします。
```
$ oc scale --replicas 2 deployment scaling

$ oc get pod -o wide

$ curl http://ルート名/
```
いかがでしょうか。

RunningのPodが2つに増えて、アクセスする度に異なるIPアドレスが表示されれば成功です。

「oc get pod -o wide」コマンドで2つのPodが稼動していれば、Webサーバーの負荷も分散されています。

<br><br>
## ①-2 ：Podのスケールアウト/自動
それでは、負荷に応じてPodの数が自動的に増えてくれるように設定します。
```
$ oc autoscale deployment/scaling --min 1 --max 8 --cpu-percent 80

$ oc get hpa
```

ここでは、scalingデプロイ設定のレプリカ設定を「最小：１」「最大：８」にして、CPUの合計使用率が８０％以下に保たれるように設定しました。

Podに負荷をかけてCPU使用率を増加させ、Pod数が自動的に増えていくか、確認してみましょう。

```
$ oc get pod
$ oc sh pod名 "cat /dev/urandum | md5sum" &
$ oc sh pod名 "cat /dev/urandum | md5sum" &
$ watch oc get pod
$ curl http://ルート名/

```

いかがでしょうか。Pod数は増えましたか。

バックグラウンドプロセスで実行させている負荷かけプロセスを停止してください。
```
$ jobs
$ kill プロセス名
```

次の手順のためにHPA設定も消しておきます。
```
$ oc get hpa
$ oc delete hpa HPA名
```


<br><br>
## ②-1 ：ノードのスケールアウト/手動
次は、Workerノードの数を３つに増やします。
oc scaleコマンドでWorkerノードのマシンセット名を指定して3つに増やしてください。
```
$ oc get node -o wide
$ oc get machineset -n openshift-machine-api
$ oc scale --replicas=3  machineset マシンセット名 -n openshift-machine-api
```

しばらく待った後、クラスタのノード数が3つに増えたことを確認します。

```
$ oc get node -o wide
$ oc get machineset -n openshift-machine-api
```

簡単にノード数を増やすことができましたね。

<br><br>
## ②-2 ：ノードのスケールアウト/自動
最後に、自動的にWorkerノード数を増加させていく方法を学びます。

まず最初に、準備作業として Cluster Autoscaler リソースを作成し、
次に実際に自動スケールさせるための Machine Autoscaler リソースを作成します。

Cluster Autoscaler リソースを作成します。

```
$ vi ClusterAutoscaler.yml
```
```
apiVersion: "autoscaling.openshift.io/v1"
kind: "ClusterAutoscaler"
metadata:
  name: "default"
spec:
  podPriorityThreshold: -10
  resourceLimits:
    maxNodesTotal: 7
  scaleDown:
    enabled: true
    delayAfterAdd: 3m
    unneededTime: 3m
```

上の設定では、Masterも含めてクラスタ全体で最大７ノード構成までを上限としています。
```
$ oc create -f ClusterAutoscaler.yml
```

openshift-machine-api 名前空間に最初のマシンセットの MachineAutoscaler リソースを作成し、マシンセットを ４ ノードにスケールアウトできるようにします。
```
$ oc get machinesets -n openshift-machine-api
```

```
$ vi machineautoscaler.yml
```

```
apiVersion: "autoscaling.openshift.io/v1beta1"
kind: "MachineAutoscaler"
metadata:
  name: "scale-automatic"
  namespace: "openshift-machine-api"
spec:
  minReplicas: 1
  maxReplicas: 4
  scaleTargetRef:
    apiVersion: machine.openshift.io/v1beta1
    kind: MachineSet
    name: マシンセット名
```
上の設定では、マシンセットに含まれるノード数を最大４としています。

```
$ oc create -f machineautoscaler.yml
$ oc get machinesets -n openshift-machine-api
```
クラスター・オートスケーラーでは、Podの要求リソースの合計に対して、ノードのリソースが不足する場合に、自動的にノード数を増やすように動作します。
```
$ oc edit deployment scaling
```
以下のようにメモリ要求リソースを増やします。
```
    spec:
      containers:
      - resources:
          requests:
            memory: "1024Mi"
```

Pod数を増やします。
```
$ oc scale --replicas 5 deployment scaling
$ oc get po
```

Podのステータスが「Pending」になるまでPod数を増やしていきます。
```
$ oc scale --replicas 6 deployment scaling
$ oc get po
```

Podのステータスが「Pending」になったら、ノードが増えるまで、しばらく待ちます。
```
$ oc get node -o wide
```

「Pending」だったPodが新しいノードにデプロイされて、ステータスが「Running」になったら成功です。
```
$ oc get pod -o wide
```



